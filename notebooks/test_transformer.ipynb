{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded length stats: {'diff_mean': 7.4578, 'diff_std': 4.97939947784871}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ParticleTransformer(\n",
       "  (length_predictor): LengthPredictor(\n",
       "    (particle_embedding): Linear(in_features=4, out_features=256, bias=False)\n",
       "    (sequence_layers): ModuleList(\n",
       "      (0-2): 3 x Sequential(\n",
       "        (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (attention): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=1, bias=False)\n",
       "      (1): Softmax(dim=1)\n",
       "    )\n",
       "    (length_head): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=False)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=128, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (particle_embedding): Linear(in_features=4, out_features=256, bias=False)\n",
       "  (sequence_layers): ModuleList(\n",
       "    (0-2): 3 x Sequential(\n",
       "      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=256, out_features=256, bias=False)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (self_attention): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=1, bias=False)\n",
       "    (3): Softmax(dim=1)\n",
       "  )\n",
       "  (final_head): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=4, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from train_particle_transformer import ParticleTransformer\n",
    "\n",
    "# Load the trained model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ParticleTransformer().to(device)\n",
    "\n",
    "# Load the saved model state\n",
    "checkpoint = torch.load('best_particle_transformer.pt', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n"
     ]
    }
   ],
   "source": [
    "import energyflow as ef\n",
    "from train_particle_transformer import ParticleDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Load test data\n",
    "print(\"Loading test data...\")\n",
    "data = ef.zjets_delphes.load(\n",
    "    \"Herwig\",\n",
    "    pad=False, \n",
    "    cache_dir=\"../data\",\n",
    "    source=\"zenodo\",\n",
    "    which=\"all\"\n",
    ")\n",
    "\n",
    "# Create test dataset\n",
    "test_sim = data[\"sim_particles\"]\n",
    "test_gen = data[\"gen_particles\"]\n",
    "test_dataset = ParticleDataset(test_sim, test_gen)\n",
    "\n",
    "# Create dataloader\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get a single batch\n",
    "batch = next(iter(test_loader))\n",
    "sim_features = batch[\"sim_features\"].to(device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sequence shape: (1, 26, 4)\n",
      "Generated sequence shape: (1, 25, 4)\n",
      "\n",
      "Simulated sequence (first 5):\n",
      "[[ 0.11039242 -0.10999276  0.333286    0.1       ]\n",
      " [ 0.02987454 -0.11790374  0.15472978  0.2       ]\n",
      " [ 0.01788264 -0.14657624  0.19709224  0.2       ]\n",
      " [ 0.01106268 -0.20399679  0.25202745  0.1       ]\n",
      " [ 0.2119501  -0.01510048 -0.03257734  0.2       ]]\n",
      "\n",
      "Generator sequence (first 5):\n",
      "[[ 0.22400826  0.00229552 -0.07039601  0.9       ]\n",
      " [ 0.0056566  -0.22012563 -0.01429803  0.2       ]\n",
      " [ 0.00815064  0.20607793 -0.07526214  1.        ]\n",
      " [ 0.03117605 -0.10038943  0.11691111  0.2       ]\n",
      " [ 0.01304285  0.10844737 -0.1567741   0.2       ]]\n",
      "\n",
      "Predicted sequence (first 5):\n",
      "[[ 0.          0.          0.          0.        ]\n",
      " [-0.00075159 -0.00068024 -0.00205913  0.00864768]\n",
      " [-0.0012172   0.00240981  0.01172171  0.04643966]\n",
      " [ 0.00589175 -0.00944618  0.03549908  0.10920764]\n",
      " [ 0.01533815 -0.02036647  0.04667786  0.13387969]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate sequence\n",
    "with torch.no_grad():\n",
    "    predicted_seq = model.generate(sim_features)\n",
    "\n",
    "# Convert to numpy for analysis\n",
    "predicted_seq = predicted_seq.cpu().numpy()\n",
    "gen_seq = batch[\"gen_features\"].numpy()[:,:batch[\"gen_length\"][0]]\n",
    "\n",
    "print(\"Predicted sequence shape:\", predicted_seq.shape)\n",
    "print(\"Generated sequence shape:\", gen_seq.shape)\n",
    "\n",
    "# Print first 5 particles of each sequence\n",
    "print(\"\\nSimulated sequence (first 5):\")\n",
    "print(sim_features[0].cpu().numpy()[:5])\n",
    "\n",
    "print(\"\\nGenerated sequence (first 5):\")\n",
    "print(gen_seq[0][:min(5, batch[\"gen_length\"][0])])\n",
    "\n",
    "print(\"\\nPredicted sequence (first 5):\") \n",
    "print(predicted_seq[0][:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgatr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
